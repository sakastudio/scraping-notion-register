import os
from openai import OpenAI
from typing import Optional

# OpenAI APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))

def generate_article_from_transcript(
    transcript: str, 
    title: str, 
    description: Optional[str] = None,
    metadata: Optional[dict] = None
) -> Optional[str]:
    """
    YouTubeå‹•ç”»ã®å­—å¹•ã‹ã‚‰æ§‹é€ åŒ–ã•ã‚ŒãŸè¨˜äº‹ã‚’ç”Ÿæˆ
    
    Args:
        transcript: å­—å¹•ãƒ†ã‚­ã‚¹ãƒˆ
        title: å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«
        description: å‹•ç”»ã®èª¬æ˜æ–‡ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        metadata: å‹•ç”»ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒãƒ£ãƒ³ãƒãƒ«åã€ã‚¿ã‚°ãªã©ï¼‰
    
    Returns:
        ç”Ÿæˆã•ã‚ŒãŸè¨˜äº‹ãƒ†ã‚­ã‚¹ãƒˆ
    """
    
    if not transcript:
        return None
    
    # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’æ§‹ç¯‰
    context_parts = [f"å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«: {title}"]
    
    if description:
        context_parts.append(f"å‹•ç”»èª¬æ˜æ–‡: {description[:500]}")
    
    if metadata:
        if metadata.get('channel'):
            context_parts.append(f"ãƒãƒ£ãƒ³ãƒãƒ«: {metadata['channel']}")
        if metadata.get('tags'):
            context_parts.append(f"ã‚¿ã‚°: {', '.join(metadata['tags'][:5])}")
    
    context = "\n".join(context_parts)
    
    # å­—å¹•ãŒé•·ã™ãã‚‹å ´åˆã¯åˆ¶é™
    max_transcript_length = 10000
    if len(transcript) > max_transcript_length:
        transcript = transcript[:max_transcript_length] + "...[ä»¥ä¸‹çœç•¥]"
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ§‹ç¯‰
    prompt = f"""ä»¥ä¸‹ã®YouTubeå‹•ç”»ã®å­—å¹•ã‹ã‚‰ã€èª­ã¿ã‚„ã™ãæ§‹é€ åŒ–ã•ã‚ŒãŸè¨˜äº‹ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã€è¦ä»¶ã€‘
1. å‹•ç”»ã®ä¸»è¦ãªãƒã‚¤ãƒ³ãƒˆã‚’æ•´ç†ã—ã¦èª¬æ˜
2. é©åˆ‡ãªè¦‹å‡ºã—ã¨ã‚»ã‚¯ã‚·ãƒ§ãƒ³åˆ†ã‘ã‚’è¡Œã†
3. é‡è¦ãªæƒ…å ±ã¯ç®‡æ¡æ›¸ãã§ã¾ã¨ã‚ã‚‹
4. ã‚²ãƒ¼ãƒ é–‹ç™ºã‚„ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã®è¦³ç‚¹ã‹ã‚‰æœ‰ç”¨ãªæ´å¯ŸãŒã‚ã‚Œã°è¿½åŠ 
5. å°‚é–€ç”¨èªã¯å¿…è¦ã«å¿œã˜ã¦ç°¡æ½”ã«èª¬æ˜
6. è¨˜äº‹ã¯æ—¥æœ¬èªã§ä½œæˆ

ã€å‹•ç”»æƒ…å ±ã€‘
{context}

ã€å­—å¹•ãƒ†ã‚­ã‚¹ãƒˆã€‘
{transcript}

ã€å‡ºåŠ›å½¢å¼ã€‘
Markdownå½¢å¼ã§ã€ä»¥ä¸‹ã®æ§‹é€ ã‚’å‚è€ƒã«è¨˜äº‹ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š

# [è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«]

## æ¦‚è¦
[å‹•ç”»ã®å†…å®¹ã‚’2-3æ–‡ã§è¦ç´„]

## ä¸»è¦ãªãƒã‚¤ãƒ³ãƒˆ
[é‡è¦ãªå†…å®¹ã‚’ç®‡æ¡æ›¸ãã§]

## è©³ç´°ãªå†…å®¹
[ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã”ã¨ã«è©³ã—ãèª¬æ˜]

## ã¾ã¨ã‚
[å…¨ä½“ã®ã¾ã¨ã‚ã¨é‡è¦ãª takeaway]

---
è¨˜äº‹ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š"""

    try:
        # OpenAI APIã‚’å‘¼ã³å‡ºã—
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": "ã‚ãªãŸã¯å„ªç§€ãªãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚YouTubeå‹•ç”»ã®å†…å®¹ã‚’åˆ†ã‹ã‚Šã‚„ã™ã„è¨˜äº‹ã«ã¾ã¨ã‚ã‚‹ã“ã¨ãŒå¾—æ„ã§ã™ã€‚"
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            max_tokens=2000,
            temperature=0.7
        )
        
        # ç”Ÿæˆã•ã‚ŒãŸè¨˜äº‹ã‚’å–å¾—
        article = response.choices[0].message.content
        
        return article
        
    except Exception as e:
        print(f"è¨˜äº‹ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None

def combine_article_and_transcript(
    article: Optional[str], 
    transcript: Optional[str],
    title: str,
    url: str,
    metadata: Optional[dict] = None
) -> str:
    """
    ç”Ÿæˆã•ã‚ŒãŸè¨˜äº‹ã¨å…ƒã®å­—å¹•ã‚’çµ„ã¿åˆã‚ã›ã¦Notionã«ç™»éŒ²ã™ã‚‹å½¢å¼ã«ã™ã‚‹
    
    Args:
        article: ç”Ÿæˆã•ã‚ŒãŸè¨˜äº‹
        transcript: å…ƒã®å­—å¹•
        title: å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«
        url: YouTube URL
        metadata: å‹•ç”»ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
    
    Returns:
        Notionç™»éŒ²ç”¨ã®å®Œå…¨ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    """
    
    content_parts = []
    
    # URLã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
    content_parts.append(f"**YouTube URL**: {url}\n")
    
    if metadata:
        if metadata.get('channel'):
            content_parts.append(f"**ãƒãƒ£ãƒ³ãƒãƒ«**: {metadata['channel']}")
        if metadata.get('upload_date'):
            content_parts.append(f"**å…¬é–‹æ—¥**: {metadata['upload_date']}")
        if metadata.get('view_count'):
            content_parts.append(f"**å†ç”Ÿå›æ•°**: {metadata['view_count']:,}")
        content_parts.append("")
    
    # ç”Ÿæˆã•ã‚ŒãŸè¨˜äº‹ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    if article:
        content_parts.append("---\n")
        content_parts.append("# ğŸ“ AIãŒç”Ÿæˆã—ãŸè¨˜äº‹\n")
        content_parts.append(article)
        content_parts.append("\n---\n")
    
    # å…ƒã®å­—å¹•ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    if transcript:
        content_parts.append("# ğŸ“‹ å…ƒã®å­—å¹•ï¼ˆãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼‰\n")
        
        # é•·ã„å­—å¹•ã¯åˆ†å‰²ã—ã¦è¡¨ç¤º
        if len(transcript) > 15000:
            content_parts.append(transcript[:15000])
            content_parts.append("\n\n*[å­—å¹•ãŒé•·ã„ãŸã‚ã€æ®‹ã‚Šã®éƒ¨åˆ†ã¯çœç•¥ã•ã‚Œã¦ã„ã¾ã™]*")
        else:
            content_parts.append(transcript)
    elif not article:
        # è¨˜äº‹ã‚‚å­—å¹•ã‚‚ãªã„å ´åˆ
        content_parts.append("*å­—å¹•ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚å‹•ç”»ã®èª¬æ˜æ–‡ã®ã¿ãŒåˆ©ç”¨å¯èƒ½ã§ã™ã€‚*")
    
    return "\n".join(content_parts)

def process_youtube_for_notion(
    title: str,
    description: Optional[str],
    transcript: Optional[str],
    url: str,
    metadata: Optional[dict] = None
) -> str:
    """
    YouTubeå‹•ç”»æƒ…å ±ã‚’å‡¦ç†ã—ã¦Notionç™»éŒ²ç”¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆ
    
    ä¸»è¦ãªå‡¦ç†ãƒ•ãƒ­ãƒ¼:
    1. å­—å¹•ãŒã‚ã‚‹å ´åˆã¯è¨˜äº‹ã‚’ç”Ÿæˆ
    2. è¨˜äº‹ã¨å­—å¹•ã‚’çµ„ã¿åˆã‚ã›ã‚‹
    3. Notionç™»éŒ²ç”¨ã®å½¢å¼ã§è¿”ã™
    """
    
    # å­—å¹•ã‹ã‚‰è¨˜äº‹ã‚’ç”Ÿæˆ
    article = None
    if transcript and len(transcript) > 100:  # å­—å¹•ãŒååˆ†ã«ã‚ã‚‹å ´åˆ
        print("å­—å¹•ã‹ã‚‰è¨˜äº‹ã‚’ç”Ÿæˆä¸­...")
        article = generate_article_from_transcript(
            transcript=transcript,
            title=title,
            description=description,
            metadata=metadata
        )
        
        if article:
            print("è¨˜äº‹ã®ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸ")
        else:
            print("è¨˜äº‹ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
    elif description and len(description) > 200:  # å­—å¹•ãŒãªã„å ´åˆã¯èª¬æ˜æ–‡ã‹ã‚‰ç”Ÿæˆ
        print("èª¬æ˜æ–‡ã‹ã‚‰è¨˜äº‹ã‚’ç”Ÿæˆä¸­...")
        article = generate_article_from_transcript(
            transcript=description,  # èª¬æ˜æ–‡ã‚’å­—å¹•ã®ä»£ã‚ã‚Šã«ä½¿ç”¨
            title=title,
            description=None,
            metadata=metadata
        )
    
    # è¨˜äº‹ã¨å­—å¹•ã‚’çµ„ã¿åˆã‚ã›ã¦Notionç”¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ä½œæˆ
    content = combine_article_and_transcript(
        article=article,
        transcript=transcript,
        title=title,
        url=url,
        metadata=metadata
    )
    
    return content

if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆç”¨
    test_transcript = """
    ã“ã‚“ã«ã¡ã¯ã€ä»Šæ—¥ã¯ã‚²ãƒ¼ãƒ é–‹ç™ºã«ãŠã‘ã‚‹é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã«ã¤ã„ã¦è©±ã—ã¾ã™ã€‚
    ã¾ãšç¬¬ä¸€ã«ã€ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ä½“é¨“ã‚’æœ€å„ªå…ˆã«è€ƒãˆã‚‹ã“ã¨ãŒå¤§åˆ‡ã§ã™ã€‚
    ã‚²ãƒ¼ãƒ ãƒ¡ã‚«ãƒ‹ã‚¯ã‚¹ã¯é¢ç™½ã•ã‚’ç”Ÿã¿å‡ºã™æ‰‹æ®µã§ã‚ã£ã¦ã€ç›®çš„ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
    æ¬¡ã«ã€ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ”ãƒ³ã‚°ã®é‡è¦æ€§ã«ã¤ã„ã¦èª¬æ˜ã—ã¾ã™ã€‚
    æ—©æœŸã«ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã‚’ä½œæˆã—ã€å®Ÿéš›ã«ãƒ—ãƒ¬ã‚¤ã—ã¦ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å¾—ã‚‹ã“ã¨ãŒæˆåŠŸã¸ã®éµã§ã™ã€‚
    """
    
    test_metadata = {
        'channel': 'ã‚²ãƒ¼ãƒ é–‹ç™ºãƒãƒ£ãƒ³ãƒãƒ«',
        'tags': ['ã‚²ãƒ¼ãƒ é–‹ç™º', 'Unity', 'ã‚¤ãƒ³ãƒ‡ã‚£ãƒ¼ã‚²ãƒ¼ãƒ '],
        'view_count': 12345,
        'upload_date': '2024-01-15'
    }
    
    # è¨˜äº‹ç”Ÿæˆã®ãƒ†ã‚¹ãƒˆ
    content = process_youtube_for_notion(
        title="ã‚²ãƒ¼ãƒ é–‹ç™ºã®åŸºæœ¬åŸå‰‡",
        description="ã“ã®ãƒ“ãƒ‡ã‚ªã§ã¯ã€æˆåŠŸã™ã‚‹ã‚²ãƒ¼ãƒ é–‹ç™ºã®ãŸã‚ã®åŸºæœ¬çš„ãªåŸå‰‡ã«ã¤ã„ã¦è§£èª¬ã—ã¾ã™ã€‚",
        transcript=test_transcript,
        url="https://youtube.com/watch?v=example",
        metadata=test_metadata
    )
    
    # çµæœã‚’ä¿å­˜
    with open("article_test.md", "w", encoding="utf-8") as f:
        f.write(content)
    
    print("ãƒ†ã‚¹ãƒˆè¨˜äº‹ã‚’ article_test.md ã«ä¿å­˜ã—ã¾ã—ãŸ")