import os
from openai import OpenAI
from typing import Optional

# OpenAI APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))


def generate_article_with_gpt5(
    transcript: str, 
    title: str, 
    description: Optional[str] = None,
    metadata: Optional[dict] = None,
    model: str = "gpt-5"  # gpt-5, gpt-5-mini, gpt-5-nano
) -> Optional[str]:
    """
    GPT-5ã‚’ä½¿ç”¨ã—ã¦YouTubeå‹•ç”»ã®å­—å¹•ã‹ã‚‰æ§‹é€ åŒ–ã•ã‚ŒãŸè¨˜äº‹ã‚’ç”Ÿæˆ
    
    Args:
        transcript: å­—å¹•ãƒ†ã‚­ã‚¹ãƒˆ
        title: å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«
        description: å‹•ç”»ã®èª¬æ˜æ–‡ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        metadata: å‹•ç”»ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒãƒ£ãƒ³ãƒãƒ«åã€ã‚¿ã‚°ãªã©ï¼‰
        model: ä½¿ç”¨ã™ã‚‹GPT-5ãƒ¢ãƒ‡ãƒ«ï¼ˆgpt-5/gpt-5-mini/gpt-5-nanoï¼‰
    
    Returns:
        ç”Ÿæˆã•ã‚ŒãŸè¨˜äº‹ãƒ†ã‚­ã‚¹ãƒˆ
    """
    
    if not transcript:
        return None
    
    # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±ã‚’æ§‹ç¯‰
    context_parts = [f"å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«: {title}"]
    
    if description:
        context_parts.append(f"å‹•ç”»èª¬æ˜æ–‡: {description[:500]}")
    
    if metadata:
        if metadata.get('channel'):
            context_parts.append(f"ãƒãƒ£ãƒ³ãƒãƒ«: {metadata['channel']}")
        if metadata.get('tags'):
            context_parts.append(f"ã‚¿ã‚°: {', '.join(metadata['tags'][:5])}")
        if metadata.get('duration'):
            duration = metadata['duration']
            hours = duration // 3600
            minutes = (duration % 3600) // 60
            if hours > 0:
                context_parts.append(f"å‹•ç”»ã®é•·ã•: {hours}æ™‚é–“{minutes}åˆ†")
            else:
                context_parts.append(f"å‹•ç”»ã®é•·ã•: {minutes}åˆ†")
    
    context = "\n".join(context_parts)
    
    # å­—å¹•ãŒé•·ã™ãã‚‹å ´åˆã¯åˆ¶é™ï¼ˆGPT-5ã¯å¤§å®¹é‡å…¥åŠ›ã«å¯¾å¿œï¼‰
    max_transcript_length = 80000  # GPT-5ã¯å¤§å®¹é‡å…¥åŠ›ã«å¯¾å¿œ
    if len(transcript) > max_transcript_length:
        transcript = transcript[:max_transcript_length] + "...[ä»¥ä¸‹çœç•¥]"
    
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ§‹ç¯‰ï¼ˆGPT-5å‘ã‘ã«æœ€é©åŒ–ï¼‰
    prompt = f"""ä»¥ä¸‹ã®YouTubeå‹•ç”»ã®å­—å¹•ã‹ã‚‰ã€èª­ã¿ã‚„ã™ãæ§‹é€ åŒ–ã•ã‚ŒãŸè¨˜äº‹ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
ã“ã®è¨˜äº‹ã¯ã‚²ãƒ¼ãƒ é–‹ç™ºè€…ã‚„ãƒãƒ¼ã‚±ã‚¿ãƒ¼ãŒèª­ã‚€ã“ã¨ã‚’æƒ³å®šã—ã¦ã„ã¾ã™ã€‚

ã€è¦ä»¶ã€‘
1. å‹•ç”»ã®æ ¸å¿ƒã¨ãªã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ˜ç¢ºã«æŠ½å‡º
2. è«–ç†çš„ãªæ§‹é€ ã§æƒ…å ±ã‚’æ•´ç†ï¼ˆå°å…¥â†’æœ¬è«–â†’çµè«–ï¼‰
3. é‡è¦ãªæ´å¯Ÿã‚„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ ã‚’å¼·èª¿
4. ã‚²ãƒ¼ãƒ é–‹ç™ºãƒ»ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã®è¦³ç‚¹ã‹ã‚‰å®Ÿè·µçš„ãªä¾¡å€¤ã‚’æä¾›
5. å°‚é–€ç”¨èªã¯é©åˆ‡ã«èª¬æ˜ã—ã€åˆå¿ƒè€…ã«ã‚‚ç†è§£ã—ã‚„ã™ã
6. å…·ä½“ä¾‹ã‚„æ•°å€¤ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°ç©æ¥µçš„ã«æ´»ç”¨
7. è¨˜äº‹ã¯æ—¥æœ¬èªã§ã€ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãªãƒˆãƒ¼ãƒ³ã§ä½œæˆ

ã€å‹•ç”»æƒ…å ±ã€‘
{context}

ã€å­—å¹•ãƒ†ã‚­ã‚¹ãƒˆã€‘
{transcript}

ã€å‡ºåŠ›å½¢å¼ã€‘
ä»¥ä¸‹ã®æ§‹é€ ã§Markdownå½¢å¼ã®è¨˜äº‹ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š

# [é­…åŠ›çš„ã§å†…å®¹ã‚’çš„ç¢ºã«è¡¨ã™ã‚¿ã‚¤ãƒˆãƒ«]

## ğŸ“Œ ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼
[3-5æ–‡ã§å‹•ç”»ã®è¦ç‚¹ã‚’ç°¡æ½”ã«ã¾ã¨ã‚ã‚‹]

## ğŸ¯ ã“ã®è¨˜äº‹ã§å­¦ã¹ã‚‹ã“ã¨
[ç®‡æ¡æ›¸ãã§3-5å€‹ã®ä¸»è¦ãªå­¦ç¿’ãƒã‚¤ãƒ³ãƒˆ]

## ğŸ“Š ä¸»è¦ãªå†…å®¹

### [ã‚»ã‚¯ã‚·ãƒ§ãƒ³1ã®ã‚¿ã‚¤ãƒˆãƒ«]
[å†…å®¹ã‚’è©³ã—ãèª¬æ˜]

### [ã‚»ã‚¯ã‚·ãƒ§ãƒ³2ã®ã‚¿ã‚¤ãƒˆãƒ«]
[å†…å®¹ã‚’è©³ã—ãèª¬æ˜]

### [ã‚»ã‚¯ã‚·ãƒ§ãƒ³3ã®ã‚¿ã‚¤ãƒˆãƒ«]
[å†…å®¹ã‚’è©³ã—ãèª¬æ˜]

## ğŸ’¡ é‡è¦ãªæ´å¯Ÿã¨ãƒã‚¤ãƒ³ãƒˆ
[å‹•ç”»ã‹ã‚‰å¾—ã‚‰ã‚Œã‚‹é‡è¦ãªæ´å¯Ÿã‚’ç®‡æ¡æ›¸ãã§]

## ğŸš€ å®Ÿè·µã¸ã®å¿œç”¨
[ã“ã®å†…å®¹ã‚’ã©ã®ã‚ˆã†ã«å®Ÿè·µã«æ´»ã‹ã›ã‚‹ã‹]

## ğŸ“ ã¾ã¨ã‚
[å…¨ä½“ã®ã¾ã¨ã‚ã¨æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³]

---
è¨˜äº‹ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š"""

    try:
        # GPT-5ã§è¨˜äº‹ç”Ÿæˆï¼ˆChat Completions APIï¼‰
        print(f"GPT-5 ({model})ã‚’ä½¿ç”¨ã—ã¦è¨˜äº‹ã‚’ç”Ÿæˆä¸­...")
        
        response = client.chat.completions.create(
            model=model,
            messages=[
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            max_completion_tokens=128000  # GPT-5ã¯æœ€å¤§128,000ãƒˆãƒ¼ã‚¯ãƒ³ã¾ã§å¯¾å¿œ
        )
        
        article = response.choices[0].message.content
        
        # ä½¿ç”¨æƒ…å ±ã®å‡ºåŠ›
        if hasattr(response, 'usage'):
            usage = response.usage
            print(f"ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ - å…¥åŠ›: {usage.prompt_tokens}, å‡ºåŠ›: {usage.completion_tokens}, åˆè¨ˆ: {usage.total_tokens}")
            
            # GPT-5ã®æ¨è«–ãƒˆãƒ¼ã‚¯ãƒ³ã‚‚è¡¨ç¤ºï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
            if hasattr(usage, 'reasoning_tokens'):
                print(f"æ¨è«–ãƒˆãƒ¼ã‚¯ãƒ³: {usage.reasoning_tokens}")
        
        print(f"GPT-5 ({model})ã§ã®ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸ")
        return article
        
    except Exception as e:
        print(f"è¨˜äº‹ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None

def process_youtube_for_notion_gpt5(
    title: str,
    description: Optional[str],
    transcript: Optional[str],
    url: str,
    metadata: Optional[dict] = None,
    model: str = "gpt-5-mini"
) -> str:
    """
    YouTubeå‹•ç”»æƒ…å ±ã‚’å‡¦ç†ã—ã¦Notionç™»éŒ²ç”¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆï¼ˆGPT-5ä½¿ç”¨ï¼‰
    
    Args:
        title: å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«
        description: å‹•ç”»èª¬æ˜æ–‡
        transcript: å­—å¹•ãƒ†ã‚­ã‚¹ãƒˆ
        url: YouTube URL
        metadata: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        model: ä½¿ç”¨ã™ã‚‹GPT-5ãƒ¢ãƒ‡ãƒ«ï¼ˆgpt-5/gpt-5-mini/gpt-5-nanoï¼‰
    
    Returns:
        Notionç™»éŒ²ç”¨ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
    """
    
    # å­—å¹•ã‹ã‚‰è¨˜äº‹ã‚’ç”Ÿæˆ
    article = None
    if transcript and len(transcript) > 100:  # å­—å¹•ãŒååˆ†ã«ã‚ã‚‹å ´åˆ
        print("GPT-5ã§å­—å¹•ã‹ã‚‰è¨˜äº‹ã‚’ç”Ÿæˆä¸­...")
        article = generate_article_with_gpt5(
            transcript=transcript,
            title=title,
            description=description,
            metadata=metadata,
            model=model
        )
        
        if article:
            print("GPT-5ã§ã®è¨˜äº‹ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸ")
        else:
            print("è¨˜äº‹ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
    
    # è¨˜äº‹ã¨å­—å¹•ã‚’çµ„ã¿åˆã‚ã›ã¦Notionç”¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ä½œæˆ
    content_parts = []
    
    # URLã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
    content_parts.append(f"**YouTube URL**: {url}\n")
    
    if metadata:
        if metadata.get('channel'):
            content_parts.append(f"**ãƒãƒ£ãƒ³ãƒãƒ«**: {metadata['channel']}")
        if metadata.get('upload_date'):
            content_parts.append(f"**å…¬é–‹æ—¥**: {metadata['upload_date']}")
        if metadata.get('view_count'):
            content_parts.append(f"**å†ç”Ÿå›æ•°**: {metadata['view_count']:,}")
        content_parts.append("")
    
    # ç”Ÿæˆã•ã‚ŒãŸè¨˜äº‹ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    if article:
        content_parts.append("---\n")
        content_parts.append("# ğŸ¤– AIåˆ†æè¨˜äº‹ï¼ˆGPT-5ç”Ÿæˆï¼‰\n")
        content_parts.append(article)
        content_parts.append("\n---\n")
    
    # å…ƒã®å­—å¹•ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆæŠ˜ã‚ŠãŸãŸã¿å¯èƒ½ãªå½¢å¼ã§ï¼‰
    if transcript:
        content_parts.append("# ğŸ“‹ å…ƒã®å­—å¹•ï¼ˆãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼‰\n")
        content_parts.append("<details>")
        content_parts.append("<summary>ã‚¯ãƒªãƒƒã‚¯ã—ã¦å­—å¹•ã‚’è¡¨ç¤º</summary>\n")
        
        # é•·ã„å­—å¹•ã¯åˆ†å‰²ã—ã¦è¡¨ç¤º
        if len(transcript) > 30000:
            content_parts.append(transcript[:30000])
            content_parts.append("\n\n*[å­—å¹•ãŒé•·ã„ãŸã‚ã€æ®‹ã‚Šã®éƒ¨åˆ†ã¯çœç•¥ã•ã‚Œã¦ã„ã¾ã™]*")
        else:
            content_parts.append(transcript)
        
        content_parts.append("\n</details>")
    elif not article:
        # è¨˜äº‹ã‚‚å­—å¹•ã‚‚ãªã„å ´åˆ
        content_parts.append("*å­—å¹•ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚å‹•ç”»ã®èª¬æ˜æ–‡ã®ã¿ãŒåˆ©ç”¨å¯èƒ½ã§ã™ã€‚*")
    
    return "\n".join(content_parts)

def process_youtube_for_notion(
    title: str,
    description: Optional[str],
    transcript: Optional[str],
    url: str,
    metadata: Optional[dict] = None,
    use_best_model: bool = True  # æœ€è‰¯ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
) -> str:
    """
    YouTubeå‹•ç”»æƒ…å ±ã‚’å‡¦ç†ã—ã¦Notionç™»éŒ²ç”¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆ
    
    ä¸»è¦ãªå‡¦ç†ãƒ•ãƒ­ãƒ¼:
    1. å­—å¹•ãŒã‚ã‚‹å ´åˆã¯è¨˜äº‹ã‚’ç”Ÿæˆ
    2. è¨˜äº‹ã¨å­—å¹•ã‚’çµ„ã¿åˆã‚ã›ã‚‹
    3. Notionç™»éŒ²ç”¨ã®å½¢å¼ã§è¿”ã™
    """
    
    return process_youtube_for_notion_gpt5(
        title=title,
        description=description,
        transcript=transcript,
        url=url,
        metadata=metadata,
        model="gpt-5"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§gpt-5-miniã‚’ä½¿ç”¨
    )


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆç”¨
    test_transcript = """
    ã“ã‚“ã«ã¡ã¯ã€ä»Šæ—¥ã¯ã‚²ãƒ¼ãƒ é–‹ç™ºã«ãŠã‘ã‚‹é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã«ã¤ã„ã¦è©±ã—ã¾ã™ã€‚
    ã¾ãšç¬¬ä¸€ã«ã€ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®ä½“é¨“ã‚’æœ€å„ªå…ˆã«è€ƒãˆã‚‹ã“ã¨ãŒå¤§åˆ‡ã§ã™ã€‚
    ã‚²ãƒ¼ãƒ ãƒ¡ã‚«ãƒ‹ã‚¯ã‚¹ã¯é¢ç™½ã•ã‚’ç”Ÿã¿å‡ºã™æ‰‹æ®µã§ã‚ã£ã¦ã€ç›®çš„ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
    æ¬¡ã«ã€ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ”ãƒ³ã‚°ã®é‡è¦æ€§ã«ã¤ã„ã¦èª¬æ˜ã—ã¾ã™ã€‚
    æ—©æœŸã«ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã‚’ä½œæˆã—ã€å®Ÿéš›ã«ãƒ—ãƒ¬ã‚¤ã—ã¦ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å¾—ã‚‹ã“ã¨ãŒæˆåŠŸã¸ã®éµã§ã™ã€‚
    """
    
    test_metadata = {
        'channel': 'ã‚²ãƒ¼ãƒ é–‹ç™ºãƒãƒ£ãƒ³ãƒãƒ«',
        'tags': ['ã‚²ãƒ¼ãƒ é–‹ç™º', 'Unity', 'ã‚¤ãƒ³ãƒ‡ã‚£ãƒ¼ã‚²ãƒ¼ãƒ '],
        'view_count': 12345,
        'upload_date': '2024-01-15'
    }
    
    # è¨˜äº‹ç”Ÿæˆã®ãƒ†ã‚¹ãƒˆ
    content = process_youtube_for_notion(
        title="ã‚²ãƒ¼ãƒ é–‹ç™ºã®åŸºæœ¬åŸå‰‡",
        description="ã“ã®ãƒ“ãƒ‡ã‚ªã§ã¯ã€æˆåŠŸã™ã‚‹ã‚²ãƒ¼ãƒ é–‹ç™ºã®ãŸã‚ã®åŸºæœ¬çš„ãªåŸå‰‡ã«ã¤ã„ã¦è§£èª¬ã—ã¾ã™ã€‚",
        transcript=test_transcript,
        url="https://youtube.com/watch?v=example",
        metadata=test_metadata
    )
    
    # çµæœã‚’ä¿å­˜
    with open("article_test.md", "w", encoding="utf-8") as f:
        f.write(content)
    
    print("ãƒ†ã‚¹ãƒˆè¨˜äº‹ã‚’ article_test.md ã«ä¿å­˜ã—ã¾ã—ãŸ")