import re
import yt_dlp
import requests
from typing import Optional, Tuple, Dict, Any, List
import re
from typing import Optional, Tuple, Dict, Any, List

import requests
import yt_dlp


def extract_video_id(url: str) -> Optional[str]:
    """YouTube URLã‹ã‚‰å‹•ç”»IDã‚’æŠ½å‡º"""
    patterns = [
        r'(?:youtube\.com\/watch\?v=|youtu\.be\/|youtube\.com\/embed\/)([a-zA-Z0-9_-]{11})',
        r'youtube\.com\/shorts\/([a-zA-Z0-9_-]{11})'
    ]
    
    for pattern in patterns:
        match = re.search(pattern, url)
        if match:
            return match.group(1)
    return None

def parse_vtt_subtitle(vtt_content: str) -> str:
    """VTTå½¢å¼ã®å­—å¹•ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«ãƒ‘ãƒ¼ã‚¹"""
    lines = vtt_content.split('\n')
    text_lines = []
    
    # VTTãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ã‚¹ã‚­ãƒƒãƒ—
    start_index = 0
    for i, line in enumerate(lines):
        if 'WEBVTT' in line:
            start_index = i + 1
            break
    
    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¨è¨­å®šè¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã‚’æŠ½å‡º
    i = start_index
    while i < len(lines):
        line = lines[i].strip()
        
        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆ00:00:00.000 --> 00:00:05.000 å½¢å¼ï¼‰
        if '-->' in line:
            i += 1
            # æ¬¡ã®ç©ºè¡Œã¾ãŸã¯ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¾ã§ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’åé›†
            while i < len(lines) and lines[i].strip() and '-->' not in lines[i]:
                text = lines[i].strip()
                # HTMLã‚¿ã‚°ã‚’é™¤å»ï¼ˆ<c>ã‚¿ã‚°ãªã©ï¼‰
                text = re.sub(r'<[^>]+>', '', text)
                # é‡è¤‡ã‚’é¿ã‘ã‚‹
                if text and (not text_lines or text != text_lines[-1]):
                    text_lines.append(text)
                i += 1
        i += 1
    
    return ' '.join(text_lines)

def parse_srt_subtitle(srt_content: str) -> str:
    """SRTå½¢å¼ã®å­—å¹•ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«ãƒ‘ãƒ¼ã‚¹"""
    lines = srt_content.split('\n')
    text_lines = []
    
    i = 0
    while i < len(lines):
        line = lines[i].strip()
        
        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—è¡Œã‚’æ¤œå‡ºï¼ˆ00:00:00,000 --> 00:00:05,000 å½¢å¼ï¼‰
        if '-->' in line:
            i += 1
            # æ¬¡ã®ç©ºè¡Œã¾ãŸã¯ç•ªå·è¡Œã¾ã§ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’åé›†
            while i < len(lines) and lines[i].strip() and not lines[i].strip().isdigit() and '-->' not in lines[i]:
                text = lines[i].strip()
                # HTMLã‚¿ã‚°ã‚’é™¤å»
                text = re.sub(r'<[^>]+>', '', text)
                # é‡è¤‡ã‚’é¿ã‘ã‚‹
                if text and (not text_lines or text != text_lines[-1]):
                    text_lines.append(text)
                i += 1
        i += 1
    
    return ' '.join(text_lines)

def download_and_parse_subtitle(subtitle_url: str, format_type: str = 'vtt') -> Optional[str]:
    """å­—å¹•URLã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãƒ‘ãƒ¼ã‚¹"""
    try:
        response = requests.get(subtitle_url, timeout=10)
        response.raise_for_status()
        content = response.text
        
        # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¿œã˜ã¦ãƒ‘ãƒ¼ã‚¹
        if format_type == 'vtt' or 'vtt' in subtitle_url:
            return parse_vtt_subtitle(content)
        elif format_type == 'srt':
            return parse_srt_subtitle(content)
        else:
            # ãã®ä»–ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¯ç”Ÿãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦è¿”ã™
            return content
            
    except Exception as e:
        print(f"å­—å¹•ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰/ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def get_best_subtitle(subtitles_dict: Dict, preferred_langs: List[str] = ['ja', 'en']) -> Optional[Tuple[str, Dict]]:
    """åˆ©ç”¨å¯èƒ½ãªå­—å¹•ã‹ã‚‰æœ€é©ãªã‚‚ã®ã‚’é¸æŠ"""
    if not subtitles_dict:
        return None
    
    # å„ªå…ˆè¨€èªé †ã«æ¢ã™
    for lang in preferred_langs:
        if lang in subtitles_dict:
            subtitle_list = subtitles_dict[lang]
            # vttå½¢å¼ã‚’å„ªå…ˆã€æ¬¡ã«srtã€ãã®ä»–
            for fmt_priority in ['vtt', 'srt', 'srv3', 'srv2', 'srv1', 'json3']:
                for subtitle_info in subtitle_list:
                    if subtitle_info.get('ext') == fmt_priority:
                        return lang, subtitle_info
            
            # å½¢å¼ã®å„ªå…ˆé †ä½ã§è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯æœ€åˆã®ã‚‚ã®ã‚’è¿”ã™
            if subtitle_list:
                return lang, subtitle_list[0]
    
    # å„ªå…ˆè¨€èªãŒãªã„å ´åˆã¯æœ€åˆã®åˆ©ç”¨å¯èƒ½ãªè¨€èªã‚’è¿”ã™
    for lang, subtitle_list in subtitles_dict.items():
        if subtitle_list:
            return lang, subtitle_list[0]
    
    return None

def fetch_youtube_info(url: str, cookies_file: str = "youtube_com_cookies.txt") -> Tuple[Optional[str], Optional[str], Optional[str], Dict[str, Any]]:
    """
    YouTubeå‹•ç”»ã®æƒ…å ±ã¨å­—å¹•ã‚’å–å¾—ï¼ˆyt-dlpã®ã¿ä½¿ç”¨ï¼‰
    
    å¼•æ•°:
        url: YouTubeå‹•ç”»ã®URL
        cookies_file: YouTubeèªè¨¼ç”¨ã®cookiesãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    
    æˆ»ã‚Šå€¤:
        tuple: (ã‚¿ã‚¤ãƒˆãƒ«, èª¬æ˜æ–‡, å­—å¹•ãƒ†ã‚­ã‚¹ãƒˆ, ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¾æ›¸)
    """
    video_id = extract_video_id(url)
    if not video_id:
        raise ValueError(f"ç„¡åŠ¹ãªYouTube URL: {url}")
    
    # yt-dlpã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³è¨­å®š
    ydl_opts = {
        'quiet': False,  # ãƒ‡ãƒãƒƒã‚°ã®ãŸã‚ä¸€æ™‚çš„ã«False
        'no_warnings': False,
        'skip_download': True,
        # å­—å¹•é–¢é€£ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        'writesubtitles': True,  # æ‰‹å‹•å­—å¹•ã‚’å–å¾—
        'writeautomaticsub': True,  # è‡ªå‹•ç”Ÿæˆå­—å¹•ã‚’å–å¾—
        'subtitleslangs': ['ja', 'en'],  # å„ªå…ˆè¨€èª
    }
    
    # cookiesãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯ä½¿ç”¨
    import os
    if os.path.exists(cookies_file):
        ydl_opts['cookiesfrombrowser'] = None  # ãƒ–ãƒ©ã‚¦ã‚¶ã®cookieã‚’ä½¿ã‚ãªã„
        ydl_opts['cookiefile'] = cookies_file
        print(f"Cookieãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨: {cookies_file}")
    
    title = None
    description = None
    metadata = {}
    transcript = None

    try:
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            # å‹•ç”»æƒ…å ±ã‚’å–å¾—
            info = ydl.extract_info(url, download=False)
    except yt_dlp.utils.DownloadError as e:
        # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ã€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæŒ‡å®šãªã—ã§å†è©¦è¡Œ
        if "Requested format is not available" in str(e):
            print("ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚¨ãƒ©ãƒ¼ã‚’å›é¿ã—ã¦å†è©¦è¡Œ...")
            ydl_opts['format'] = None  # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæŒ‡å®šã‚’å‰Šé™¤
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                info = ydl.extract_info(url, download=False)
        else:
            raise

    # åŸºæœ¬æƒ…å ±ã‚’å–å¾—
    title = info.get('title', '')
    description = info.get('description', '')

    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’åé›†
    metadata = {
        'channel': info.get('uploader', ''),
        'channel_id': info.get('channel_id', ''),
        'duration': info.get('duration', 0),
        'view_count': info.get('view_count', 0),
        'like_count': info.get('like_count', 0),
        'upload_date': info.get('upload_date', ''),
        'tags': info.get('tags', []),
        'categories': info.get('categories', []),
        'thumbnail': info.get('thumbnail', ''),
        'video_id': video_id,
        'url': url
    }

    # å­—å¹•ã‚’å–å¾—
    print(f"åˆ©ç”¨å¯èƒ½ãªå­—å¹•ã‚’ç¢ºèªä¸­...")

    # æ‰‹å‹•å­—å¹•ã‚’å„ªå…ˆçš„ã«å–å¾—
    subtitles = info.get('subtitles', {})
    subtitle_info = None
    subtitle_lang = None

    if subtitles:
        print(f"æ‰‹å‹•å­—å¹•ãŒåˆ©ç”¨å¯èƒ½: {list(subtitles.keys())}")
        result = get_best_subtitle(subtitles, ['ja', 'en'])
        if result:
            subtitle_lang, subtitle_info = result

    # æ‰‹å‹•å­—å¹•ãŒãªã„å ´åˆã¯è‡ªå‹•ç”Ÿæˆå­—å¹•ã‚’å–å¾—
    if not subtitle_info:
        auto_captions = info.get('automatic_captions', {})
        if auto_captions:
            print(f"è‡ªå‹•ç”Ÿæˆå­—å¹•ãŒåˆ©ç”¨å¯èƒ½: {list(auto_captions.keys())}")
            result = get_best_subtitle(auto_captions, ['ja', 'en'])
            if result:
                subtitle_lang, subtitle_info = result

    # å­—å¹•ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãƒ‘ãƒ¼ã‚¹
    if subtitle_info and 'url' in subtitle_info:
        print(f"å­—å¹•ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­... (è¨€èª: {subtitle_lang}, å½¢å¼: {subtitle_info.get('ext', 'unknown')})")
        transcript = download_and_parse_subtitle(
            subtitle_info['url'],
            subtitle_info.get('ext', 'vtt')
        )

        if transcript:
            print(f"å­—å¹•ã®å–å¾—ã«æˆåŠŸã—ã¾ã—ãŸï¼ˆ{len(transcript)}æ–‡å­—ï¼‰")
        else:
            print("å­—å¹•ã®ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸ")
    else:
        print("åˆ©ç”¨å¯èƒ½ãªå­—å¹•ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")


    return title, description, transcript, metadata

def format_youtube_content(title: str, description: str, transcript: str, metadata: Dict[str, Any]) -> str:
    """
    YouTubeå‹•ç”»ã®æƒ…å ±ã‚’Markdownå½¢å¼ã§æ•´å½¢
    """
    content_parts = []
    
    # å‹•ç”»æƒ…å ±ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    content_parts.append("## å‹•ç”»æƒ…å ±")
    content_parts.append(f"**ã‚¿ã‚¤ãƒˆãƒ«**: {title}")
    content_parts.append(f"**ãƒãƒ£ãƒ³ãƒãƒ«**: {metadata.get('channel', 'ä¸æ˜')}")
    content_parts.append(f"**å…¬é–‹æ—¥**: {metadata.get('upload_date', 'ä¸æ˜')}")
    content_parts.append(f"**å†ç”Ÿå›æ•°**: {metadata.get('view_count', 0):,}")
    content_parts.append(f"**é«˜è©•ä¾¡æ•°**: {metadata.get('like_count', 0):,}")
    
    duration = metadata.get('duration', 0)
    if duration:
        hours = duration // 3600
        minutes = (duration % 3600) // 60
        seconds = duration % 60
        if hours > 0:
            content_parts.append(f"**å‹•ç”»ã®é•·ã•**: {hours}æ™‚é–“{minutes}åˆ†{seconds}ç§’")
        else:
            content_parts.append(f"**å‹•ç”»ã®é•·ã•**: {minutes}åˆ†{seconds}ç§’")
    
    if metadata.get('tags'):
        content_parts.append(f"**ã‚¿ã‚°**: {', '.join(metadata['tags'][:10])}")
    
    content_parts.append("")
    
    # èª¬æ˜æ–‡ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    if description:
        content_parts.append("## èª¬æ˜æ–‡")
        content_parts.append(description[:1000])  # æœ€åˆã®1000æ–‡å­—
        if len(description) > 1000:
            content_parts.append("...")
        content_parts.append("")
    
    # å­—å¹•ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    if transcript:
        content_parts.append("## å­—å¹•ãƒ»ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
        # é•·ã„å­—å¹•ã¯é©åˆ‡ã«åˆ†å‰²
        if len(transcript) > 5000:
            content_parts.append(transcript[:5000])
            content_parts.append("\n[å­—å¹•ãŒé•·ã„ãŸã‚çœç•¥ã•ã‚Œã¦ã„ã¾ã™...]")
        else:
            content_parts.append(transcript)
    else:
        content_parts.append("## å­—å¹•ãƒ»ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
        content_parts.append("*å­—å¹•ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“*")
    
    return "\n".join(content_parts)

if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆç”¨
    test_urls = [
        "https://www.youtube.com/watch?v=dQw4w9WgXcQ",  # Never Gonna Give You Up
        "https://youtu.be/dQw4w9WgXcQ",
    ]
    
    for test_url in test_urls[:1]:  # æœ€åˆã®1ã¤ã ã‘ãƒ†ã‚¹ãƒˆ
        print(f"\nãƒ†ã‚¹ãƒˆ URL: {test_url}")
        print("-" * 50)
        
        try:
            title, description, transcript, metadata = fetch_youtube_info(test_url)
            
            if title:
                print(f"âœ… ã‚¿ã‚¤ãƒˆãƒ«: {title}")
                print(f"ğŸ“ èª¬æ˜æ–‡ã®é•·ã•: {len(description) if description else 0}æ–‡å­—")
                print(f"ğŸ“„ å­—å¹•ã®é•·ã•: {len(transcript) if transcript else 0}æ–‡å­—")
                print(f"ğŸ“º ãƒãƒ£ãƒ³ãƒãƒ«: {metadata.get('channel', 'ä¸æ˜')}")
                print(f"ğŸ‘ï¸ å†ç”Ÿå›æ•°: {metadata.get('view_count', 0):,}")
                
                # Markdownå½¢å¼ã§ä¿å­˜
                content = format_youtube_content(title, description, transcript, metadata)
                with open("youtube_test.md", "w", encoding="utf-8") as f:
                    f.write(content)
                print("\nğŸ“ youtube_test.md ã«ä¿å­˜ã—ã¾ã—ãŸ")
                
                # å­—å¹•ã®æœ€åˆã®éƒ¨åˆ†ã‚’è¡¨ç¤º
                if transcript:
                    print("\nå­—å¹•ã®æœ€åˆã®éƒ¨åˆ†:")
                    print("-" * 30)
                    print(transcript[:500] + "..." if len(transcript) > 500 else transcript)
            else:
                print("âŒ å‹•ç”»æƒ…å ±ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
                
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()